# Paper List
**Subject to Change: The paper team and professors reserve the right to modify the following paper list throughout the semester as they may agree at a later date.**

## Table of Contents
[Overall Comments](#overall-comments)
[Additional Resources](#additional-resources)

## Overall Comments



## Some Keywords to Understand



## Presenters' Challenge: Meaningful UQ



## Uncertainty Quantification Fundamentals
1. Y. Gal and Z. Ghahramani, “Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning,” in Proceedings of The 33rd International Conference on Machine Learning, M. F. Balcan and K. Q. Weinberger, Eds., in Proceedings of Machine Learning Research, vol. 48. New York, New York, USA: PMLR, 20--22 Jun 2016, pp. 1050–1059.
1. M. Teye, H. Azizpour, and K. Smith, “Bayesian Uncertainty Estimation for Batch Normalized Deep Networks,” in Proceedings of the 35th International Conference on Machine Learning, J. Dy and A. Krause, Eds., in Proceedings of Machine Learning Research, vol. 80. PMLR, 10--15 Jul 2018, pp. 4907–4916.
1. R. Zhang, C. Li, J. Zhang, C. Chen, and A. G. Wilson, “Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning,” arXiv [cs.LG], Feb. 11, 2019. [Online]. Available: http://arxiv.org/abs/1902.03932
Note: This is a highly cited paper that builds off multiple works not mentioned in this paper list.
1. S. Hernández, D. Vergara, M. Valdenegro-Toro, and F. Jorquera, “Improving predictive uncertainty estimation using Dropout–Hamiltonian Monte Carlo,” Soft Computing, vol. 24, no. 6, pp. 4307–4322, Mar. 2020.
Note: This isn’t well-cited but demonstrates a way to combine two techniques. At face value, they appear to have good analysis of data/model evaluation.
1. T. Salimans, D. Kingma, and M. Welling, “Markov Chain Monte Carlo and Variational Inference: Bridging the Gap,” in Proceedings of the 32nd International Conference on Machine Learning, F. Bach and D. Blei, Eds., in Proceedings of Machine Learning Research, vol. 37. Lille, France: PMLR, 07--09 Jul 2015, pp. 1218–1226.
1. V. Böhm, F. Lanusse, and U. Seljak, “Uncertainty Quantification with Generative Models,” arXiv [stat.ML], Oct. 22, 2019. [Online]. Available: http://arxiv.org/abs/1910.10046
1. A. Foong, D. Burt, Y. Li, and R. Turner, “On the Expressiveness of Approximate Inference in Bayesian Neural Networks,” in Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, Eds., Curran Associates, Inc., 2020, pp. 15897–15908.
1. C. Blundell, J. Cornebise, K. Kavukcuoglu, and D. Wierstra, “Weight Uncertainty in Neural Networks,” vol. 37, pp. 1613–1622, 07--09 Jul 2015.
1. Lakshminarayanan B, Pritzel A, Blundell C,  “Simple and scalable predictive uncertainty estimation using deep ensembles,” in Advances in neural information processing systems 30, 2017.
1. Ovadia Y, Fertig E, Ren J, Nado Z, Sculley D, Nowozin S, Dillon J, Lakshminarayanan B, Snoek J, “Can you trust your model’s uncertainty? Evaluating predictive uncertainty under dataset shift,” in Advances in neural information processing systems 32, 2019.



## Current Methodologies


## Future Directions and Possibilities


## Additional Resources
**These are not open for Journal Club presentations** but are provided for quick reference to background information that may aid the group in understanding related topics.

